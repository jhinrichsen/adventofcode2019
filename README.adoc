= Advent of Code 2019
:doctype: book
:toc: macro
:sectnums:

image:https://godoc.org/gitlab.com/jhinrichsen/adventofcode2019?status.svg["godoc", link="https://godoc.org/gitlab.com/jhinrichsen/adventofcode2019"]
image:https://goreportcard.com/badge/gitlab.com/jhinrichsen/adventofcode2019["Go report card", link="https://goreportcard.com/report/gitlab.com/jhinrichsen/adventofcode2019"]
image:https://gitlab.com/jhinrichsen/adventofcode2019/badges/master/pipeline.svg[link="https://gitlab.com/jhinrichsen/adventofcode2019/-/commits/master",title="pipeline status"]
image:https://gitlab.com/jhinrichsen/adventofcode2019/badges/master/coverage.svg[link="https://gitlab.com/jhinrichsen/adventofcode2019/-/jobs",title="coverage report"]
image:https://img.shields.io/badge/runtime-0.85s-blue["runtime"]

toc::[]

My take on https://adventofcode.com/2019[Advent of Code 2019] in Go.

== Build from source

----
$ go get gitlab.com/jhinrichsen/adventofcode2019
----

== Hardware

Benchmarks in this repository were run on different hardware:

- Intel Xeon @ 2.60GHz: GitLab CI runner infrastructure
- AMD Ryzen 7 7840HS: Framework 16 laptop
- Intel Core i7-14700: Desktop

Absolute numbers are not comparable across machines, but each benchstat comparison (before/after) is always run on the same machine, so relative improvements are valid.

== Overview

Number of tries for a correct answer:

|===
| Day | Part 1 | Part 2 | Title

| 1   |   1    |   1    | The Tyranny of the Rocket Equation
| 2   |   1    |   1    | 1202 Program Alarm
| 3   |   1    |   1    | Crossed Wires
| 4   |   1    |   1    | Secure Container
| 5   |   2    |   2    | Sunny with a Chance of Asteroids
| 6   |   1    |   1    | Universal Orbit Map
| 7   |   1    |   1    | Amplification Circuit
| 8   |   1    |   1    | Space Image Format
| 9   |   1    |   1    | Sensor Boost
| 10  |   1    |   1    | Monitoring Station
| 11  |   1    |   1    | Space Police
| 12  |   1    |   -    | The N-Body Problem
| 13  |   1    |   1    | Care Package
| 14  |   3    |   1    | Space Stoichiometry
| 15  |   1    |   1    | Oxygen System
| 16  |   1    |   1    | Flawed Frequency Transmission
| 17  |   1    |   1    | Set and Forget
| 18  |   2    |   1    | Many-Worlds Interpretation
| 19  |   1    |   4    | Tractor Beam
| 20  |   1    |   2    | Donut Maze
| 21  |   1    |   1    | Springdroid Adventure
| 22  |   2    |   1    | Slam Shuffle
| 23  |   1    |   1    | Category Six
| 24  |   1    |   1    | Planet of Discord
| 25  |   1    |   -    | Cryostasis

|===

== Day 01: The Tyranny of the Rocket Equation

Refactored to use iterative loop instead of goto for recursive fuel calculation.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: Intel(R) Xeon(R) CPU @ 2.60GHz
              │     b0      │                 b2                 │
              │   sec/op    │   sec/op     vs base               │
Day01Part1-16   823.2n ± 2%   862.7n ± 4%   +4.80% (p=0.000 n=8)
Day01Part2-16   2.345µ ± 1%   1.818µ ± 2%  -22.51% (p=0.000 n=8)
geomean         1.390µ        1.252µ        -9.89%
----

Part 2 shows 22.5% speedup from eliminating goto and using direct uint iteration.

== Day 02: 1202 Program Alarm

Migrated to unified Intcode implementation. The new Intcode module provides a common
VM for all 12 Intcode-based days (2, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25).

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │     b0      │               b1                │
              │   sec/op    │   sec/op     vs base            │
Day02Part1-16   1.055µ ± 1%   1.095µ ± 3%  +3.79% (p=0.001 n=8)
Day02Part2-16   597.0µ ± 2%   627.0µ ± 2%  +5.03% (p=0.001 n=8)

              │     b0      │              b1               │
              │    B/op     │    B/op     vs base           │
Day02Part1-16   3.968Ki ± 0%   2.578Ki ± 0%  -35.03% (p=0.001 n=8)
Day02Part2-16   3.968Ki ± 0%   2.578Ki ± 0%  -35.03% (p=0.001 n=8)
----

Small time regression (5%) but 35% memory reduction from optimized inline parsing.

== Day 03: Crossed Wires

Replaced point-by-point marking with line segment intersection algorithm.
Instead of marking every point in maps (millions of entries), represent wires
as line segments and compute horizontal-vertical intersections directly.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │ /tmp/day03_b0.txt │         /tmp/day03_b1.txt          │
              │      sec/op       │   sec/op     vs base               │
Day03Part1-16       37686.0µ ± 6%   203.3µ ± 2%  -99.46% (p=0.000 n=8)
Day03Part2-16       40937.2µ ± 4%   203.6µ ± 1%  -99.50% (p=0.000 n=8)
geomean               39.28m        203.4µ       -99.48%

              │ /tmp/day03_b0.txt │          /tmp/day03_b1.txt          │
              │       B/op        │     B/op      vs base               │
Day03Part1-16     27313.96Ki ± 0%   81.25Ki ± 0%  -99.70% (p=0.000 n=8)
Day03Part2-16     27316.51Ki ± 0%   81.25Ki ± 0%  -99.70% (p=0.000 n=8)
geomean              26.68Mi        81.25Ki       -99.70%

              │ /tmp/day03_b0.txt │         /tmp/day03_b1.txt         │
              │     allocs/op     │ allocs/op   vs base               │
Day03Part1-16       2070.000 ± 0%   4.000 ± 0%  -99.81% (p=0.000 n=8)
Day03Part2-16       2099.000 ± 0%   4.000 ± 0%  -99.81% (p=0.000 n=8)
geomean               2.084k        4.000       -99.81%
----

== Day 04: Secure Container

Optimized by reusing digit buffer and inlining criteria checks.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: Intel(R) Xeon(R) CPU @ 2.60GHz
              │      b0      │                 b1                 │
              │    sec/op    │   sec/op     vs base               │
Day04Part1-16   20.536m ± 3%   5.115m ± 2%  -75.09% (p=0.000 n=8)
Day04Part2-16   18.314m ± 3%   5.289m ± 4%  -71.12% (p=0.000 n=8)
geomean          19.39m        5.202m       -73.18%

              │      b0      │                    b1                    │
              │     B/op     │     B/op      vs base                    │
Day04Part1-16   4.190Mi ± 0%   0.000Mi ± 0%  -100.00% (p=0.000 n=8)
Day04Part2-16   4.190Mi ± 0%   0.000Mi ± 0%  -100.00% (p=0.000 n=8)

              │     b0      │                  b1                   │
              │  allocs/op  │ allocs/op  vs base                    │
Day04Part1-16   549.2k ± 0%   0.0k ± 0%  -100.00% (p=0.000 n=8)
Day04Part2-16   549.2k ± 0%   0.0k ± 0%  -100.00% (p=0.000 n=8)
----

75% speedup with 100% memory reduction by reusing single digit buffer instead of allocating 549k times.

== Day 06: Universal Orbit Map

Optimized with inline parsing and memoization.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │ /tmp/day06_b0.txt │         /tmp/day06_b1.txt          │
              │      sec/op       │   sec/op     vs base               │
Day06Part1-16        2323.3µ ± 2%   114.1µ ± 2%  -95.09% (p=0.000 n=8)
Day06Part2-16         454.4µ ± 1%   418.7µ ± 1%   -7.86% (p=0.000 n=8)
geomean               1.027m        218.6µ       -78.72%

              │ /tmp/day06_b0.txt │         /tmp/day06_b1.txt         │
              │     allocs/op     │ allocs/op   vs base               │
Day06Part1-16        1063.00 ± 0%   11.00 ± 0%  -98.97% (p=0.000 n=8)
Day06Part2-16       1063.000 ± 0%   6.000 ± 0%  -99.44% (p=0.000 n=8)
geomean               1.063k        8.124       -99.24%
----

== Day 07: Amplification Circuit

Migrated to unified Intcode implementation, eliminating goroutines and channels.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │     b0       │                b1                │
              │   sec/op     │   sec/op     vs base             │
Day07Part1-16   1040.0µ ± 3%    63.4µ ± 2%  -93.90% (p=0.000 n=8)
Day07Part2-16   1930.0µ ± 3%   508.0µ ± 2%  -73.68% (p=0.000 n=8)

              │     b0       │               b1                │
              │    B/op      │    B/op     vs base             │
Day07Part1-16   2.608Mi ± 0%   0.013Mi ± 0%  -99.50% (p=0.000 n=8)
Day07Part2-16   2.608Mi ± 0%   2.514Mi ± 0%   -3.60% (p=0.000 n=8)

              │     b0      │              b1               │
              │ allocs/op   │ allocs/op   vs base           │
Day07Part1-16   2571.0 ± 0%   604.0 ± 0%  -76.51% (p=0.000 n=8)
Day07Part2-16   2585.0 ± 0%   1204.0 ± 0%  -53.42% (p=0.000 n=8)
----

Part 1: 16x faster, 99.5% less memory. Part 2: 3.8x faster, eliminated channel overhead.

== Day 09: Sensor Boost

Migrated to unified Intcode implementation.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │     b0      │               b1               │
              │   sec/op    │   sec/op     vs base           │
Day09Part1-16    28.0µ ± 4%   15.2µ ± 2%  -45.71% (p=0.000 n=8)
Day09Part2-16   4140.0µ ± 2%  2200.0µ ± 1%  -46.86% (p=0.000 n=8)

              │     b0      │             b1              │
              │ allocs/op   │ allocs/op   vs base         │
Day09Part1-16   23.00 ± 0%   10.00 ± 0%  -56.52% (p=0.000 n=8)
Day09Part2-16   44.00 ± 0%   31.00 ± 0%  -29.55% (p=0.000 n=8)
----

Both parts 1.9x faster, 30-57% fewer allocations.

== Day 10: Monitoring Station

Optimized asteroid visibility detection by replacing expensive floating-point operations with integer-based GCD normalization.

.Key changes
- Replaced `complex128` coordinates with integer `Asteroid{X, Y int}` struct
- Part 1: GCD-based direction normalization instead of `cmplx.Polar()` and `math.Atan2()`
- Part 2: Squared distance for sorting (avoiding `math.Sqrt()`), simplified vaporization algorithm
- Eliminated `cmplx.Abs()` calls in hot path

.Performance impact
----
              │     b2      │                 b3                 │
              │   sec/op    │   sec/op     vs base               │
Day10Part1-16   7.856m ± 4%   5.703m ± 5%  -27.40% (p=0.000 n=8)
Day10Part2-16   8.138m ± 2%   5.833m ± 3%  -28.33% (p=0.000 n=8)

              │     b2      │                 b3                  │
              │  allocs/op  │ allocs/op   vs base                 │
Day10Part1-16    948.0 ± 0%   948.0 ± 0%        ~ (p=1.000 n=8)
Day10Part2-16   1606.0 ± 0%   971.0 ± 0%  -39.54% (p=0.000 n=8)
----

== Day 11: Space Police

Migrated to unified Intcode implementation.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │     b0      │               b1               │
              │   sec/op    │   sec/op     vs base           │
Day11Part1-16   3580.0µ ± 2%  1108.0µ ± 2%  -69.05% (p=0.000 n=8)
Day11Part2-16    359.0µ ± 5%   214.0µ ± 1%  -40.39% (p=0.000 n=8)
----

Part 1: 3.2x faster. Part 2: 1.7x faster. Eliminated goroutine/channel overhead.

== Day 12: The N-Body Problem

Optimized cycle detection by checking return to initial state instead of storing full history.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │ /tmp/day12_b0.txt │         /tmp/day12_b1.txt          │
              │      sec/op       │   sec/op     vs base               │
Day12Part2-16         44.80m ± 1%   10.25m ± 3%  -77.13% (p=0.000 n=8)

              │ /tmp/day12_b0.txt │          /tmp/day12_b1.txt          │
              │       B/op        │    B/op      vs base                │
Day12Part2-16        90.05Mi ± 0%   0.00Mi ± 0%  -100.00% (p=0.000 n=8)

              │ /tmp/day12_b0.txt │          /tmp/day12_b1.txt          │
              │     allocs/op     │  allocs/op   vs base                │
Day12Part2-16         2.316k ± 0%   0.000k ± 0%  -100.00% (p=0.000 n=8)
----

== Day 13: Care Package

Migrated to unified Intcode implementation, eliminating goroutine/channel overhead.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │     b0      │               b1               │
              │   sec/op    │   sec/op     vs base           │
Day13Part1-16    381.0µ ± 2%  123.0µ ± 2%  -67.72% (p=0.000 n=8)
Day13Part2-16   13200.0µ ± 2%  4680.0µ ± 2%  -64.55% (p=0.000 n=8)
----

Part 1: 3.1x faster. Part 2: 2.8x faster. Eliminated channel overhead with step-based execution.

== Day 14: Space Stoichiometry

Optimized with inline parsing (avoiding strings.Fields allocations) and map reuse for binary search in Part 2.

----
              │ /tmp/day14_b0.txt │          /tmp/day14_b1.txt          │
              │      sec/op       │    sec/op     vs base               │
Day14Part2-16         1.284m ± 2%   1.090m ±  2%  -15.10% (p=0.000 n=8)

              │ /tmp/day14_b0.txt │          /tmp/day14_b1.txt          │
              │       B/op        │     B/op      vs base               │
Day14Part2-16       163.10Ki ± 0%   31.02Ki ± 0%  -80.98% (p=0.000 n=8)

              │ /tmp/day14_b0.txt │         /tmp/day14_b1.txt         │
              │     allocs/op     │ allocs/op   vs base               │
Day14Part2-16          676.0 ± 0%   202.0 ± 0%  -70.12% (p=0.000 n=8)
----

== Day 15: Oxygen System

Migrated to unified Intcode implementation, eliminating goroutine/channel overhead.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │     b0      │               b1               │
              │   sec/op    │   sec/op     vs base           │
Day15Part1-16   31.0m ± 2%   17.8m ± 2%  -42.58% (p=0.000 n=8)
Day15Part2-16   40.0m ± 2%   22.0m ± 2%  -45.00% (p=0.000 n=8)
----

Part 1: 1.7x faster. Part 2: 1.8x faster. Eliminated channel overhead with step-based execution.

== Day 16: Flawed Frequency Transmission

Optimized Part 1 FFT algorithm using prefix sums for O(1) range queries instead of O(n) per-element iteration, plus slice reuse between phases.

----
              │ /tmp/day16_b0.txt │         /tmp/day16_b1.txt          │
              │      sec/op       │   sec/op     vs base               │
Day16Part1-16       83293.6µ ± 2%   619.7µ ± 5%  -99.26% (p=0.000 n=8)

              │ /tmp/day16_b0.txt │          /tmp/day16_b1.txt          │
              │       B/op        │     B/op      vs base               │
Day16Part1-16       530.47Ki ± 0%   15.75Ki ± 0%  -97.03% (p=0.000 n=8)

              │ /tmp/day16_b0.txt │         /tmp/day16_b1.txt          │
              │     allocs/op     │  allocs/op   vs base               │
Day16Part1-16       103.000 ±  6%   3.000 ±  0%  -97.09% (p=0.000 n=8)
----

134x speedup (83ms to 620µs) by processing blocks with prefix sums instead of iterating every element.

== Day 18: Many-Worlds Interpretation

Optimized Part 1 from full-maze BFS to key-graph Dijkstra. Instead of BFS on every grid cell, precompute distances between keys and search the much smaller key-state space.

----
              │ /tmp/day18_b0.txt │          /tmp/day18_b1.txt           │
              │      sec/op       │    sec/op      vs base               │
Day18Part1-16         2.775 ± ∞ ¹     1.573 ± ∞ ¹  -43.32% (p=0.029 n=4)

              │ /tmp/day18_b0.txt │          /tmp/day18_b1.txt           │
              │       B/op        │     B/op       vs base               │
Day18Part1-16     1519.72Mi ± ∞ ¹   20.40Mi ± ∞ ¹  -98.66% (p=0.029 n=4)

              │ /tmp/day18_b0.txt │          /tmp/day18_b1.txt          │
              │     allocs/op     │  allocs/op    vs base               │
Day18Part1-16       33.107k ± ∞ ¹   1.801k ± ∞ ¹  -94.56% (p=0.029 n=4)
----

Reduced memory from 1.5GB to 20MB by searching key-graph instead of full grid.

== Day 20: Donut Maze

Optimized Part 2 by using struct keys for visited map instead of fmt.Sprintf strings.

----
              │ /tmp/day20_b0.txt │           /tmp/day20_b1.txt           │
              │      sec/op       │    sec/op     vs base                 │
Day20Part2-16        763.1m ± ∞ ¹   451.4m ± ∞ ¹  -40.85%

              │ /tmp/day20_b0.txt │            /tmp/day20_b1.txt            │
              │     allocs/op     │  allocs/op    vs base                   │
Day20Part2-16      1151.96k ± ∞ ¹   11.97k ± ∞ ¹  -98.96%
----

99% fewer allocations by avoiding string formatting in hot path.

== Day 19: Tractor Beam

Part 2 required multiple algorithmic iterations to find the correct approach:

*Failed approaches:*
- Attempt 1: Checking bottom-right corner instead of top-right
- Attempt 2: Checking both top-right and bottom-left from top-left corner
- Attempt 3: Optimization that incorrectly skipped beam points

*Successful approach:*
- Scan rows as the BOTTOM edge of the 100x100 square
- For each row y, find the leftmost beam point (bottom-left corner)
- Check if the top-right corner at (x+99, y-99) is also in the beam
- Return the top-left corner coordinates (x, y-99)

This approach works because the tractor beam expands monotonically, making a
row-by-row bottom-edge scan both correct and efficient.

=== Performance Optimizations

Optimized by eliminating channel overhead and implementing direct IntCode execution.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: Intel(R) Xeon(R) CPU @ 2.60GHz
                │       b0        │                  b1                   │
                │     sec/op      │    sec/op      vs base                │
Day19Part1-16     127.1m ±  0%     76.5m ± 10%   -39.81% (p=0.000 n=1+8)
Day19Part2-16     25478.9m ±  0%    103.5m ±  6%   -99.59% (p=0.000 n=1+8)
geomean           1.801            88.88m         -95.07%

                │        b0        │                  b1                   │
                │       B/op       │      B/op       vs base               │
Day19Part1-16     155.5Mi ±  0%    147.6Mi ± 0%    -5.08% (p=0.000 n=1+8)
Day19Part2-16     35.0Gi ±  0%      0.2Gi ± 0%   -99.44% (p=0.000 n=1+8)
geomean           2.333Gi          492.5Mi        -78.91%

                │      b0       │                  b1                   │
                │   allocs/op   │  allocs/op   vs base                  │
Day19Part1-16     48.008k ±  0%   40.509k ± 0%   -15.62% (p=0.000 n=1+8)
Day19Part2-16     11796.278k ± 0%   55.234k ± 0%   -99.53% (p=0.000 n=1+8)
geomean           756.4k           47.94k         -93.66%
----

Key optimizations:

1. *Direct IntCode execution*: Replaced channel-based Day5 processor with inline `runBeamTest` function
   - Eliminated goroutine and channel synchronization overhead
   - Reduced allocations by avoiding channel buffers

2. *Incremental leftX tracking*: Track leftmost beam x-coordinate from previous row
   - Beam expands monotonically, so no need to search from x=0 each iteration
   - Significantly reduces redundant beam tests in Part 2

3. *Memory efficiency*: Inline execution uses stack allocation instead of heap
   - Part 2 reduced from 35GB to 200MB (99.4% reduction)
   - Part 2 allocations reduced from 11.8M to 55K (99.5% reduction)

Results: Part 2 speedup of 245x (from 25.5s to 0.104s), making Day 19 no longer the dominant bottleneck.


== Day 22: Slam Shuffle

=== Part 2 Integer Overflow Bug

*Problem*: Initial implementation produced incorrect answer (69676926565412, too high).

*Root Cause*: Integer overflow in modular multiplication when handling large deck size (119315717514047).

*Where*: The `modMul` function was using direct multiplication `(a % m) * (b % m) % m`, which overflows when both operands are close to the modulus value. Since int64 max ≈ 9.2×10^18 and the deck size is ≈ 1.2×10^14, multiplying two values near the deck size exceeds int64 capacity.

*Why It Failed*: During matrix exponentiation in `powerTransform`, coefficients `a` and `b` grow to values near the deck size. When `modMul(a, currA, mod)` is called with both values ≈ 10^14, the intermediate result ≈ 10^28 overflows, producing incorrect results due to two's complement wraparound.

*Fix*: Implemented binary multiplication (peasant multiplication) for large values:
- Fast path: Direct multiplication for values < 1 billion (guaranteed no overflow)
- Slow path: Binary multiplication using repeated addition and doubling for large values
- Similar to how modular exponentiation avoids overflow using repeated squaring

*Impact*:
- Incorrect answer: 69676926565412
- Correct answer: 58348342289943
- All 4 example tests passed (deck size 10, small enough to avoid overflow)
- Issue only manifested with Part 2's large deck size

*Tests Added*:
- `TestDay22InverseLogic`: Validates inverse transformation for all 4 examples
- `TestDay22MultipleShuffles`: Verifies power transform with 1, 2, 3, 5, 10 shuffles

*Key Lesson*: When implementing modular arithmetic algorithms for competitive programming:
1. Always consider overflow even when using modulo operations
2. Test with actual problem constraints, not just examples
3. Binary multiplication is essential for large moduli (> √(int64_max))

== Day 24: Planet of Discord

Optimized Part 2 recursive grid simulation using precomputed neighbor masks and slice-based level storage.

----
goos: linux
goarch: amd64
pkg: gitlab.com/jhinrichsen/adventofcode2019
cpu: AMD Ryzen 7 7840HS w/ Radeon 780M Graphics
              │ /tmp/day24_b0 │           /tmp/day24_b1            │
              │    sec/op     │   sec/op     vs base               │
Day24Part2-16    19.523m ± 2%   2.002m ± 1%  -89.74% (p=0.000 n=8)

              │ /tmp/day24_b0 │            /tmp/day24_b1             │
              │     B/op      │     B/op      vs base                │
Day24Part2-16    1.142Mi ± 0%   0.000Mi ± 0%  -100.00% (p=0.000 n=8)

              │ /tmp/day24_b0 │            /tmp/day24_b1            │
              │   allocs/op   │  allocs/op   vs base                │
Day24Part2-16     2.172k ± 0%   0.000k ± 0%  -100.00% (p=0.000 n=8)
----

Key optimizations:

1. Replaced `map[int]uint` with slice indexed by level+offset
   - Map overhead eliminated (hash lookups → direct array access)
   - Double-buffering for zero allocations per iteration

2. Precomputed neighbor lookup table (`day24Neighbors[25]`)
   - Each cell stores bitmasks for same-level, outer-level, and inner-level neighbors
   - Eliminates runtime direction iteration and boundary checks

3. Used `bits.OnesCount32` for population count
   - Single CPU instruction (POPCNT) vs 25-iteration loop
   - Applied for both neighbor counting and final bug counting

10x speedup (20ms → 2ms) with 100% allocation elimination.

== Benchmarks

=== Current (AMD Ryzen 7 7840HS)

Results from `make total`:

[source]
----
include::benches/linux-amd64-AMD-Ryzen-7-7840HS-w-Radeon-780M-Graphics.txt[]
----

Total runtime: 0.73s

=== Historical (Intel Xeon @ 2.60GHz)

Original benchmark before optimizations (217s total):

[source]
----
include::benches/linux-amd64-IntelR_XeonR.txt[]
----

== SAST (Static Application Security Testing)

This project uses custom SAST tooling in GitLab CI, optimized for the free tier.

=== GitLab Free Tier Limitations

GitLab's built-in SAST features (Security Dashboard, vulnerability management, merge request security widgets) require the Ultimate tier. On the free tier, SAST scans can run but results are only available as downloadable JSON artifacts.

=== Current Setup

Our CI pipeline uses:

- Code Quality Reports: golangci-lint → JSON → banyansecurity/golint-convert → CodeClimate JSON format
  * Displays findings in merge request Code Quality widget (available in free tier since GitLab 13.2)
  * Shows code quality degradations/improvements directly in MRs

- Test Reports: go-junit-report/v2 → JUnit XML format
  * Integrates test results into GitLab's test report UI

- Coverage Reports: gocover-cobertura → Cobertura XML format  
  * Shows coverage metrics and trends in merge requests

- Vulnerability Scanning: govulncheck (periodic, scheduled pipeline)
  * Scans for known vulnerabilities in Go dependencies
  * Runs on a schedule to catch newly disclosed vulnerabilities
  * Results available as JSON artifacts (no UI on free tier)

=== Note on Deprecation

GitLab deprecated its built-in CodeClimate scanning template in version 17.3 (planned removal in 19.0). This only affects GitLab's bundled scanning engine. Custom pipelines that generate CodeClimate-format JSON (like ours) continue to work and are the recommended approach for free tier users.

The Code Quality widget will continue to display results from custom CodeClimate JSON reports.
